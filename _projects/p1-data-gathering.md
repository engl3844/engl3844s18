---
title: "Data Collection for Your Data-Story"
collection: projects
permalink: /projects/p1-data-gathering/
points: "100"
startdate: 2017-08-28
enddate: 2017-09-25
imgurl: /images/posavec-data-gathering.png
imgurl2: /images/posavec-dataset-meaningmaking.png
---

<ul class="project-top-info">
  <li>
    <b>Timeframe</b>: 08/28 &ndash; 09/10</li>
  <li>
    <b>Points</b>: 100</li>
</ul>

## Description

[Datafication](https://en.wikipedia.org/wiki/Datafication) represents the recent trend for an increased use of digital technology and media to collect, organize, and analyze data about ourselves. Most of these insights, however, are not shared with us as users and are commodified in unregulated ways, which have produced numerous social consequences and questionable ethics.<sup>[1](https://www.npr.org/sections/thetwo-way/2017/08/29/547113818/uber-ends-its-controversial-post-ride-tracking-of-users-location),[2](https://www.revealnews.org/article/uber-said-it-protects-you-from-spying-security-sources-say-otherwise/),[3](https://www.propublica.org/article/facebook-advertising-discrimination-housing-race-sex-national-origin),[4](https://www.ted.com/talks/zeynep_tufekci_we_re_building_a_dystopia_just_to_make_people_click_on_ads),[5](http://www.businessinsider.com/netflix-says-some-people-are-watching-a-christmas-prince-every-day-2017-12),[6](https://www.propublica.org/article/governors-and-federal-agencies-are-blocking-accounts-on-facebook-and-twitter?utm_campaign=sprout&utm_medium=social&utm_source=twitter&utm_content=1512769907),[7](https://medium.com/startup-grind/how-the-trump-campaign-built-an-identity-database-and-used-facebook-ads-to-win-the-election-4ff7d24269ac),[8](http://www.bbc.com/news/av/magazine-40852227/the-digital-guru-who-helped-donald-trump-to-the-presidency),[9](https://hackernoon.com/more-than-a-million-pro-repeal-net-neutrality-comments-were-likely-faked-e9f0e3ed36a6)</sup> To better prepare you as citizens and professionals, we will respond to this datafication with a project that challenges you to learn how digital media and data are intertwined, since businesses produce data sets as integral texts about our everyday communication activities. Accordingly, this project involves collecting data for 5 days about your everyday digital media practices.

This data set is necessary to complete all of the subsequent media projects in this course. Your data set will serve as the inventive seed by which your datastory's narrative grows. In particular, the analysis of your data will shape the direction, quality, and design of your data visualization. To note, the main aim of this data collection is **NOT** statistical insight nor applying quasi-experimental design strategies, but to explore, examine, and gain insight into your writing practices and how digital media and data permeate it. In doing so, we will try to understand how digital media performs and communicates much more than what we may have originally thought.

To guide us through this process, we will all share the following broader research question: **How are our media practices linked with algorithmic audiences**? From there, each of you must choose and refine a particular topic as a path to explore one of your own prominent, digital media practices. Some past projects included the following topics:

- Emotions felt as: Browsing Instagram feed, Texting
- News engagement, e.g., overall, on Twitter, or with news apps on mobile phone.
- Use of emojis
- How I use Spotify's machine-learning suggestion features
- Netflix viewing habits

Please note that these are but previous examples that may or may not suit your lifestyle. For a successful project, you need to consider projects that will enable you to collect at least ~10 observations per day. This will provide you with data for analysis.

## General process

<figure id="twitter-css-body" class="figure-inline proj-img">
  <img src="/images/deardata-data-process-1.png" alt="Excerpt from Lupi &amp; Posavec (2016, pp. 286&ndash;287) about how to conduct the basic steps to collect data." />
  <figcaption>
    Caption: Excerpt from Lupi &amp; Posavec (2016, pp. 286&ndash;287) about how to conduct the basic steps to collect data.
  </figcaption>
</figure>

Like any good project, this one begins with a simple, personal felt dissonance&mdash;a provocation that cannot be ignored. From there, you will do the following to complete your data collection:

<ol class="visual-list">
  <li>
    <img class="image" src="/images/3844-datastory-topos.png" alt="Data-gathering image" />
    <div class="content">
      <h3>Consider &amp; combine topos</h3>
      <p>
        Define the basic parameters of your study through an invention process that plays with topics of import.</p>
    </div>
  </li>
  <li>
    <img class="image" src="/images/deardata-data-process-question.jpg" alt="How to distill a good set of questions." />
    <div class="content">
      <h3>Distill your data-story topic as research question(s)</h3>
      <p>Refine the topical parameters of your study with a sharp set of questions.</p>
    </div>
  </li>
  <li>
    <img class="image" src="/images/deardata-data-process-collectionplan.png" alt="Plan for data collection." />
    <div class="content">
      <h3>Plan data-collection strategies</h3>
      <p>Learn how to create a balance of well-planned and creative set of techniques.</p>
    </div>
  </li>
  <li>
    <img class="image" src="/images/posavec-data-gathering.png" alt="Collect the data." />
    <div class="content">
      <h3>Collect your data</h3>
      <p>Gather the data with your well-planned set of techniques, leaving room for creative hacks along the way!</p>
    </div>
  </li>
</ol>

## Rubric

<ul>
  <li>
    Data integrity: If necessary, logs changes, modifications, and/or omissions with data collection
  </li>
  <li>
    Data types: Demonstrates knowledge of [nominal](https://en.wikipedia.org/wiki/Level_of_measurement#Nominal_level) and [ordinal](https://en.wikipedia.org/wiki/Ordinal_data) data, and a good mix of the 2 types.
  </li>
  <li>
    Consistently log your data in a Google Sheets spreadsheet every evening</li>
  <li>
    Follows basic <i>tidy data</i> guidelines:
      <ul>
        <li><b>Rows</b>: Clear unit indexed per row: Every instance that I do X; no spaces between rows.</li>
        <li><b>Columns</b>: Meaningful column names; First column designated for unique identifier; Definitions applied with the notes feature; Format and arrangement of columns help outside readers and yourself understand and use the data.</li>
        <li><b>Cells</b>: 1 value, consistency of values, modify sheet according to redundancies, and limited amount of more complex cell data (1 preferable; 2 at the most)</li>
        <li><b>Sheets features</b>: Meaningful uses of some spreadsheet features: conditional formatting, frozen header, etc.</li>
      </ul>
  </li>
  <li>
    If deemed important for future consideration, contextualize datapoints with notes about the moment.</li>
</ul>
